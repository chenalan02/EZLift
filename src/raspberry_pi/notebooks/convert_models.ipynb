{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 19.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# model_path = r\"C:\\Users\\chena\\Desktop\\EZLift\\model_training\\runs\\detect\\pallets\\weights\\best.pt\"\n",
    "# model_path = '/home/pi/EZLift/model_training/runs/detect/pallets/weights/best_ncnn_model'\n",
    "# model_path = '/home/pi/EZLift/model_training/runs/detect/pallets/weights/best_saved_model/best_float16.tflite'\n",
    "\n",
    "# model_path = r\"/home/pi/EZLift/model_training/runs/detect/pallets_256/weights/best.pt\"\n",
    "# model_path = r\"/home/pi/EZLift/model_training/runs/detect/pallets_256/weights/best_ncnn_model\"\n",
    "\n",
    "# model_path = r\"C:\\Users\\chena\\Desktop\\EZLift\\model_training\\runs\\detect\\pallets_640\\weights\\best.pt\"\n",
    "\n",
    "# model = YOLO(model_path)\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.81  Python-3.9.21 torch-2.6.0 CPU (11th Gen Intel Core(TM) i7-11700 2.50GHz)\n",
      "WARNING  INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
      "WARNING:tensorflow:From c:\\Users\\chena\\anaconda3\\envs\\tflite\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.1s, saved as 'yolov8n.onnx' (12.3 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=coco8.yaml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning C:\\Users\\chena\\Desktop\\EZLift\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m WARNING  >300 images recommended for INT8 calibration, found 4 images.\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.20.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  67.4s, saved as 'yolov8n_saved_model' (41.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'yolov8n_saved_model\\yolov8n_int8.tflite' (3.3 MB)\n",
      "\n",
      "Export complete (67.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\chena\\Desktop\\EZLift\\src\\raspberry_pi\\notebooks\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n_saved_model\\yolov8n_int8.tflite imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=yolov8n_saved_model\\yolov8n_int8.tflite imgsz=640 data=coco.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n_saved_model\\\\yolov8n_int8.tflite'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.export(format=\"ncnn\")\n",
    "# model.export(format=\"tflite\", int8=True) \n",
    "# model.export(format=\"edgetpu\") # doesnt work on windows lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
