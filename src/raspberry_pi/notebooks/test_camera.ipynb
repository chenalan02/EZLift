{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from picamera2 import Picamera2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"/home/pi/EZLift/src/raspberry_pi/256_edgetpu.tflite\"\n",
    "\n",
    "model = YOLO(model_path, task='detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import cv2\n",
    "\n",
    "# picam2 = Picamera2()\n",
    "# picam2.preview_configuration.main.size = (3280, 2464)\n",
    "# picam2.preview_configuration.main.format = \"RGB888\"\n",
    "# picam2.preview_configuration.align()\n",
    "# picam2.configure(\"preview\")\n",
    "# picam2.start()\n",
    "# picam2.start(show_preview=False)\n",
    "# frame = picam2.capture_array()\n",
    "\n",
    "# with open(\"frame.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(frame, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1:32:51.072165044] [2781] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:327 \u001b[0mlibcamera v0.4.0+53-29156679\n",
      "[1:32:51.110554943] [2798] \u001b[1;33m WARN \u001b[1;37mRPiSdn \u001b[1;34msdn.cpp:40 \u001b[0mUsing legacy SDN tuning - please consider moving SDN inside rpi.denoise\n",
      "[1:32:51.112379844] [2798] \u001b[1;33m WARN \u001b[1;37mRPI \u001b[1;34mvc4.cpp:393 \u001b[0mMismatch between Unicam and CamHelper for embedded data usage!\n",
      "[1:32:51.113004669] [2798] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:447 \u001b[0mRegistered camera /base/soc/i2c0mux/i2c@1/imx219@10 to Unicam device /dev/media0 and ISP device /dev/media1\n",
      "[1:32:51.113050427] [2798] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpipeline_base.cpp:1121 \u001b[0mUsing configuration file '/usr/share/libcamera/pipeline/rpi/vc4/rpi_apps.yaml'\n",
      "[1:32:51.124154201] [2781] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1202 \u001b[0mconfiguring streams: (0) 3264x2464-RGB888 (1) 3280x2464-SBGGR10_CSI2P\n",
      "[1:32:51.124581676] [2798] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mvc4.cpp:622 \u001b[0mSensor: /base/soc/i2c0mux/i2c@1/imx219@10 - Selected sensor format: 3280x2464-SBGGR10_1X10 - Selected unicam format: 3280x2464-pBAA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/pi/EZLift/src/raspberry_pi/256_edgetpu.tflite on device 0 for TensorFlow Lite Edge TPU inference...\n",
      "\n",
      "0: 256x256 (no detections), 77.0ms\n",
      "Speed: 82.3ms preprocess, 77.0ms inference, 92.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 0.13\n",
      "\n",
      "0: 256x256 (no detections), 32.4ms\n",
      "Speed: 2.8ms preprocess, 32.4ms inference, 3.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 7.37\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 3.5ms preprocess, 23.0ms inference, 3.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 11.92\n",
      "\n",
      "0: 256x256 (no detections), 26.9ms\n",
      "Speed: 2.3ms preprocess, 26.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.02\n",
      "\n",
      "0: 256x256 (no detections), 21.5ms\n",
      "Speed: 2.3ms preprocess, 21.5ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 18.39\n",
      "\n",
      "0: 256x256 (no detections), 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 12.69\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 3.2ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.91\n",
      "\n",
      "0: 256x256 (no detections), 24.1ms\n",
      "Speed: 3.2ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.11\n",
      "\n",
      "0: 256x256 (no detections), 24.4ms\n",
      "Speed: 2.7ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.18\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 3.4ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.46\n",
      "\n",
      "0: 256x256 (no detections), 25.9ms\n",
      "Speed: 3.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.55\n",
      "\n",
      "0: 256x256 (no detections), 23.8ms\n",
      "Speed: 3.2ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.71\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 3.4ms preprocess, 23.2ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.31\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 3.2ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.09\n",
      "\n",
      "0: 256x256 (no detections), 21.6ms\n",
      "Speed: 2.4ms preprocess, 21.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.96\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.0ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.73\n",
      "\n",
      "0: 256x256 (no detections), 22.4ms\n",
      "Speed: 2.5ms preprocess, 22.4ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.91\n",
      "\n",
      "0: 256x256 (no detections), 21.6ms\n",
      "Speed: 2.4ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.46\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 3.2ms preprocess, 22.8ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.19\n",
      "\n",
      "0: 256x256 (no detections), 23.9ms\n",
      "Speed: 2.1ms preprocess, 23.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.14\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 3.3ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.28\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.8ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.67\n",
      "\n",
      "0: 256x256 (no detections), 22.4ms\n",
      "Speed: 2.5ms preprocess, 22.4ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.28\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 2.6ms preprocess, 23.2ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.32\n",
      "\n",
      "0: 256x256 (no detections), 23.1ms\n",
      "Speed: 3.5ms preprocess, 23.1ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.39\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 2.6ms preprocess, 23.2ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.81\n",
      "\n",
      "0: 256x256 (no detections), 21.4ms\n",
      "Speed: 2.6ms preprocess, 21.4ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.57\n",
      "\n",
      "0: 256x256 (no detections), 21.4ms\n",
      "Speed: 3.0ms preprocess, 21.4ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.63\n",
      "\n",
      "0: 256x256 (no detections), 21.7ms\n",
      "Speed: 2.6ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.20\n",
      "\n",
      "0: 256x256 (no detections), 21.3ms\n",
      "Speed: 2.7ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.22\n",
      "\n",
      "0: 256x256 (no detections), 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.28\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 2.8ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.84\n",
      "\n",
      "0: 256x256 (no detections), 21.4ms\n",
      "Speed: 3.2ms preprocess, 21.4ms inference, 3.1ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.08\n",
      "\n",
      "0: 256x256 (no detections), 21.9ms\n",
      "Speed: 2.7ms preprocess, 21.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.68\n",
      "\n",
      "0: 256x256 (no detections), 21.2ms\n",
      "Speed: 1.9ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.23\n",
      "\n",
      "0: 256x256 (no detections), 21.6ms\n",
      "Speed: 1.9ms preprocess, 21.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.30\n",
      "\n",
      "0: 256x256 (no detections), 21.0ms\n",
      "Speed: 2.4ms preprocess, 21.0ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.27\n",
      "\n",
      "0: 256x256 (no detections), 21.3ms\n",
      "Speed: 2.0ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.30\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 2.6ms preprocess, 23.0ms inference, 3.2ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.85\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.0ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.89\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.5ms preprocess, 22.9ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.95\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 1.8ms preprocess, 22.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.98\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 2.9ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.02\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.9ms preprocess, 22.9ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.43\n",
      "\n",
      "0: 256x256 (no detections), 23.8ms\n",
      "Speed: 4.5ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.03\n",
      "\n",
      "0: 256x256 (no detections), 22.0ms\n",
      "Speed: 3.1ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.05\n",
      "\n",
      "0: 256x256 (no detections), 22.4ms\n",
      "Speed: 3.1ms preprocess, 22.4ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.93\n",
      "\n",
      "0: 256x256 (no detections), 22.0ms\n",
      "Speed: 2.7ms preprocess, 22.0ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.34\n",
      "\n",
      "0: 256x256 (no detections), 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.07\n",
      "\n",
      "0: 256x256 (no detections), 21.3ms\n",
      "Speed: 1.9ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.67\n",
      "\n",
      "0: 256x256 (no detections), 23.5ms\n",
      "Speed: 2.3ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.45\n",
      "\n",
      "0: 256x256 (no detections), 23.4ms\n",
      "Speed: 2.0ms preprocess, 23.4ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.26\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 2.6ms preprocess, 23.6ms inference, 3.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.30\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 3.1ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.16\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 2.6ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.22\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.05\n",
      "\n",
      "0: 256x256 (no detections), 24.4ms\n",
      "Speed: 2.6ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.17\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 4.4ms preprocess, 22.8ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.92\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 4.3ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.78\n",
      "\n",
      "0: 256x256 (no detections), 23.4ms\n",
      "Speed: 2.1ms preprocess, 23.4ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.19\n",
      "\n",
      "0: 256x256 (no detections), 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.37\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 1.9ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.03\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 2.4ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.65\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 2.8ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.81\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 2.4ms preprocess, 23.6ms inference, 3.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.86\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.8ms preprocess, 22.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.79\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.05\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 2.8ms preprocess, 22.2ms inference, 3.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.92\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 3.0ms preprocess, 22.9ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.10\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 2.2ms preprocess, 23.0ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.21\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.3ms preprocess, 22.9ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.04\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.09\n",
      "\n",
      "0: 256x256 (no detections), 23.5ms\n",
      "Speed: 2.7ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.17\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 2.5ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.89\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 3.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.22\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 1.9ms preprocess, 22.8ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.70\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.90\n",
      "\n",
      "0: 256x256 (no detections), 22.3ms\n",
      "Speed: 2.5ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.63\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 2.5ms preprocess, 22.8ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.57\n",
      "\n",
      "0: 256x256 (no detections), 22.3ms\n",
      "Speed: 2.5ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.26\n",
      "\n",
      "0: 256x256 (no detections), 23.9ms\n",
      "Speed: 1.9ms preprocess, 23.9ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.69\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 3.5ms preprocess, 22.8ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.28\n",
      "\n",
      "0: 256x256 (no detections), 23.6ms\n",
      "Speed: 2.4ms preprocess, 23.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.85\n",
      "\n",
      "0: 256x256 (no detections), 26.4ms\n",
      "Speed: 4.6ms preprocess, 26.4ms inference, 3.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 13.29\n",
      "\n",
      "0: 256x256 (no detections), 23.8ms\n",
      "Speed: 5.0ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 14.81\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 3.7ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.75\n",
      "\n",
      "0: 256x256 (no detections), 21.7ms\n",
      "Speed: 3.5ms preprocess, 21.7ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 18.23\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 3.4ms preprocess, 23.0ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.06\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 3.5ms preprocess, 22.6ms inference, 4.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.88\n",
      "\n",
      "0: 256x256 (no detections), 22.0ms\n",
      "Speed: 2.9ms preprocess, 22.0ms inference, 6.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.09\n",
      "\n",
      "0: 256x256 (no detections), 22.1ms\n",
      "Speed: 3.0ms preprocess, 22.1ms inference, 3.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 18.05\n",
      "\n",
      "0: 256x256 (no detections), 21.2ms\n",
      "Speed: 3.3ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.23\n",
      "\n",
      "0: 256x256 (no detections), 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.16\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 2.5ms preprocess, 23.2ms inference, 3.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.29\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 3.0ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.43\n",
      "\n",
      "0: 256x256 (no detections), 23.9ms\n",
      "Speed: 3.0ms preprocess, 23.9ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.46\n",
      "\n",
      "0: 256x256 (no detections), 23.4ms\n",
      "Speed: 2.1ms preprocess, 23.4ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.86\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.8ms preprocess, 22.6ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.00\n",
      "\n",
      "0: 256x256 (no detections), 21.2ms\n",
      "Speed: 4.2ms preprocess, 21.2ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.40\n",
      "\n",
      "0: 256x256 (no detections), 21.4ms\n",
      "Speed: 2.4ms preprocess, 21.4ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.41\n",
      "\n",
      "0: 256x256 (no detections), 21.2ms\n",
      "Speed: 2.9ms preprocess, 21.2ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.28\n",
      "\n",
      "0: 256x256 (no detections), 21.3ms\n",
      "Speed: 2.2ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.43\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 3.2ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.09\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 3.1ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.56\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.1ms preprocess, 22.9ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.38\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 3.1ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.27\n",
      "\n",
      "0: 256x256 (no detections), 22.3ms\n",
      "Speed: 2.0ms preprocess, 22.3ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.93\n",
      "\n",
      "0: 256x256 (no detections), 22.1ms\n",
      "Speed: 2.1ms preprocess, 22.1ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.77\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 2.6ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.63\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 2.8ms preprocess, 23.7ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.85\n",
      "\n",
      "0: 256x256 (no detections), 23.5ms\n",
      "Speed: 2.5ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.04\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.6ms preprocess, 22.9ms inference, 4.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.63\n",
      "\n",
      "0: 256x256 (no detections), 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 3.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.64\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 2.8ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.88\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.32\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 1.9ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.65\n",
      "\n",
      "0: 256x256 (no detections), 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.49\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.3ms preprocess, 22.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.55\n",
      "\n",
      "0: 256x256 (no detections), 22.9ms\n",
      "Speed: 2.9ms preprocess, 22.9ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.72\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.85\n",
      "\n",
      "0: 256x256 (no detections), 22.1ms\n",
      "Speed: 2.1ms preprocess, 22.1ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.15\n",
      "\n",
      "0: 256x256 (no detections), 21.4ms\n",
      "Speed: 2.4ms preprocess, 21.4ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.71\n",
      "\n",
      "0: 256x256 (no detections), 21.3ms\n",
      "Speed: 2.5ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.95\n",
      "\n",
      "0: 256x256 (no detections), 21.5ms\n",
      "Speed: 2.2ms preprocess, 21.5ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.38\n",
      "\n",
      "0: 256x256 (no detections), 21.7ms\n",
      "Speed: 2.2ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.27\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 1.9ms preprocess, 22.7ms inference, 4.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.30\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.6ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.57\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.93\n",
      "\n",
      "0: 256x256 (no detections), 22.6ms\n",
      "Speed: 2.5ms preprocess, 22.6ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.13\n",
      "\n",
      "0: 256x256 (no detections), 24.1ms\n",
      "Speed: 3.4ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.46\n",
      "\n",
      "0: 256x256 (no detections), 24.0ms\n",
      "Speed: 2.7ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.19\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 2.0ms preprocess, 22.7ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.14\n",
      "\n",
      "0: 256x256 (no detections), 22.7ms\n",
      "Speed: 3.9ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.95\n",
      "\n",
      "0: 256x256 (no detections), 21.7ms\n",
      "Speed: 2.1ms preprocess, 21.7ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.88\n",
      "\n",
      "0: 256x256 (no detections), 21.9ms\n",
      "Speed: 2.1ms preprocess, 21.9ms inference, 3.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.68\n",
      "\n",
      "0: 256x256 (no detections), 23.0ms\n",
      "Speed: 2.7ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 17.29\n",
      "\n",
      "0: 256x256 (no detections), 21.8ms\n",
      "Speed: 2.6ms preprocess, 21.8ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.97\n",
      "\n",
      "0: 256x256 (no detections), 21.1ms\n",
      "Speed: 2.8ms preprocess, 21.1ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.44\n",
      "\n",
      "0: 256x256 (no detections), 22.0ms\n",
      "Speed: 2.7ms preprocess, 22.0ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.94\n",
      "\n",
      "0: 256x256 (no detections), 21.6ms\n",
      "Speed: 3.8ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.33\n",
      "\n",
      "0: 256x256 (no detections), 22.5ms\n",
      "Speed: 2.2ms preprocess, 22.5ms inference, 2.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.72\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 1.9ms preprocess, 22.8ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.21\n",
      "\n",
      "0: 256x256 (no detections), 23.3ms\n",
      "Speed: 2.0ms preprocess, 23.3ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.90\n",
      "\n",
      "0: 256x256 (no detections), 22.2ms\n",
      "Speed: 3.1ms preprocess, 22.2ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.48\n",
      "\n",
      "0: 256x256 (no detections), 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.94\n",
      "\n",
      "0: 256x256 1 person, 22.0ms\n",
      "Speed: 2.2ms preprocess, 22.0ms inference, 52.1ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 6.30\n",
      "\n",
      "0: 256x256 (no detections), 22.4ms\n",
      "Speed: 3.2ms preprocess, 22.4ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 14.97\n",
      "\n",
      "0: 256x256 (no detections), 21.1ms\n",
      "Speed: 2.3ms preprocess, 21.1ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.22\n",
      "\n",
      "0: 256x256 (no detections), 22.8ms\n",
      "Speed: 2.3ms preprocess, 22.8ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.32\n",
      "\n",
      "0: 256x256 (no detections), 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 2.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.33\n",
      "\n",
      "0: 256x256 (no detections), 20.9ms\n",
      "Speed: 2.5ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.47\n",
      "\n",
      "0: 256x256 (no detections), 21.0ms\n",
      "Speed: 1.9ms preprocess, 21.0ms inference, 2.9ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 16.11\n",
      "\n",
      "0: 256x256 (no detections), 23.7ms\n",
      "Speed: 2.4ms preprocess, 23.7ms inference, 3.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "FPS: 15.40\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run YOLO inference on the frame with imgsz=192\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# results = model.predict(frame, device=\"tpu:0\", imgsz=192)\u001b[39;00m\n\u001b[32m     20\u001b[39m frame = cv2.resize(frame, (\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtpu:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Visualize the results on the frame\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# annotated_frame = results[0].plot()\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Calculate FPS\u001b[39;00m\n\u001b[32m     28\u001b[39m end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/ultralytics/engine/model.py:560\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/ultralytics/engine/predictor.py:175\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/torch/utils/_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = gen.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/ultralytics/engine/predictor.py:261\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.embed:\n\u001b[32m    263\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/ultralytics/engine/predictor.py:145\u001b[39m, in \u001b[36mBasePredictor.inference\u001b[39m\u001b[34m(self, im, *args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[32m    140\u001b[39m visualize = (\n\u001b[32m    141\u001b[39m     increment_path(\u001b[38;5;28mself\u001b[39m.save_dir / Path(\u001b[38;5;28mself\u001b[39m.batch[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).stem, mkdir=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.visualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.tensor)\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    144\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:704\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed)\u001b[39m\n\u001b[32m    702\u001b[39m     im = (im / scale + zero_point).astype(details[\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m])  \u001b[38;5;66;03m# de-scale\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[38;5;28mself\u001b[39m.interpreter.set_tensor(details[\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m], im)\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m y = []\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_details:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EZLift/env/lib/python3.11/site-packages/tflite_runtime/interpreter.py:941\u001b[39m, in \u001b[36mInterpreter.invoke\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke the interpreter.\u001b[39;00m\n\u001b[32m    930\u001b[39m \n\u001b[32m    931\u001b[39m \u001b[33;03mBe sure to set the input sizes, allocate tensors and fill values before\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m \u001b[33;03m  ValueError: When the underlying interpreter fails raise ValueError.\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;28mself\u001b[39m._ensure_safe()\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "picam2 = Picamera2()\n",
    "picam2.preview_configuration.main.size = (3280, 2464)\n",
    "picam2.preview_configuration.main.format = \"RGB888\"\n",
    "picam2.preview_configuration.align()\n",
    "picam2.configure(\"preview\")\n",
    "picam2.start()\n",
    "picam2.start(show_preview=False)\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    frame = picam2.capture_array()\n",
    "\n",
    "    # Run YOLO inference on the frame with imgsz=192\n",
    "    # results = model.predict(frame, device=\"tpu:0\", imgsz=192)\n",
    "    frame = cv2.resize(frame, (256, 256))\n",
    "    results = model.predict(frame, device=\"tpu:0\", imgsz=256)\n",
    "\n",
    "\n",
    "    # Visualize the results on the frame\n",
    "    # annotated_frame = results[0].plot()\n",
    "\n",
    "    # Calculate FPS\n",
    "    end_time = time.time()\n",
    "    fps = 1.0 / (end_time - start_time)\n",
    "    \n",
    "    # Overlay the FPS on the annotated frame\n",
    "    # cv2.putText(annotated_frame, f\"FPS: {fps:.2f}\", (10, 30), \n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    # cv2.imshow(\"Camera\", annotated_frame)\n",
    "\n",
    "    # Print FPS to the console (optional)\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "    # # Break the loop if 'q' is pressed\n",
    "    # if cv2.waitKey(1) == ord(\"q\"):\n",
    "    #     break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 256x256 6 persons, 29.4ms\n",
      "Speed: 5.8ms preprocess, 29.4ms inference, 12.9ms postprocess per image at shape (1, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "input_path = r\"/home/pi/EZLift/src/raspberry_pi/notebooks/test_imgs/istockphoto-1318934972-612x612.jpg\"\n",
    "img = cv2.imread(input_path)\n",
    "img = cv2.resize(img, (256, 256))\n",
    "results = model.predict(img, device=\"tpu:0\", imgsz=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = results[0].boxes\n",
    "x1, y1, x2, y2 = boxes[0].xyxy[0].cpu().numpy()\n",
    "x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "conf = boxes[0].conf[0].cpu().numpy()\n",
    "cls_id = int(boxes[0].cls[0].cpu().numpy())\n",
    "\n",
    "bb_crop = results[0].orig_img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
